

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Preprocessing &mdash; MAIIA 0.0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Models" href="models.html" />
    <link rel="prev" title="Datasets" href="datasets.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> MAIIA
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Segmentation models:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="datasets.html">Datasets</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Preprocessing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#training-pipelines">Training pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="#inference-pipelines">Inference pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="#custom-pipelines-for-specific-datasets">Custom pipelines for specific datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#image-augmentation-transformers">Image augmentation transformers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="models.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="training.html">Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="polygonisation.html">Polygonisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="misc.html">Miscellaneous</a></li>
</ul>
<p class="caption"><span class="caption-text">Main package:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="gim_cv.html">gim_cv package</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MAIIA</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Preprocessing</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/preprocessing.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="preprocessing">
<h1>Preprocessing<a class="headerlink" href="#preprocessing" title="Permalink to this headline">¶</a></h1>
<p>The <code class="xref py py-mod docutils literal notranslate"><span class="pre">preprocessing</span></code> module contains the machinery needed
to convert large raw raster arrays (extracted via the
<code class="xref py py-mod docutils literal notranslate"><span class="pre">interfaces</span></code> module) into training- (or inference-) ready
arrays. Its primary role is then to turn these large raster and mask arrays with
shapes <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">W,</span> <span class="pre">C)</span></code> and <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">W,</span> <span class="pre">C')</span></code> into <code class="docutils literal notranslate"><span class="pre">N</span></code> corresponding small
patches with shapes <code class="docutils literal notranslate"><span class="pre">(N,</span> <span class="pre">h,</span> <span class="pre">w,</span> <span class="pre">C)</span></code> and <code class="docutils literal notranslate"><span class="pre">(N,</span> <span class="pre">h,</span> <span class="pre">w,</span> <span class="pre">C')</span></code>, and to carry out
any necessary padding, type conversion, overlapping and selection of channels.</p>
<p>This is accomplished through a series of custom <a class="reference external" href="https://scikit-learn.org/stable/data_transforms.html">scikit-learn</a> transformers
assembled into pipelines. These act on and return dask arrays.</p>
<p>Since RGB images and masks are treated a little differently (with respect to
e.g. data normalisation) there are separate but similar pipelines which act
simultaneously on the raw raster data and the ground truth masks.</p>
<p>Ultimately one such preprocessing pipeline will be allocated to each image
or mask in a given dataset, converting each source file into a sequence of
model-ready patches. Concatenation, shuffling, etc are carried
out downstream by the <a class="reference internal" href="training.html"><span class="doc">Training</span></a> and <a class="reference internal" href="inference.html"><span class="doc">Inference</span></a> interfaces.</p>
<section id="training-pipelines">
<h2>Training pipelines<a class="headerlink" href="#training-pipelines" title="Permalink to this headline">¶</a></h2>
<p>An instance of the default training pipeline for images can be easily
constructed with the function
<code class="xref py py-func docutils literal notranslate"><span class="pre">get_image_training_pipeline()</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gim_cv.preprocessing</span> <span class="kn">import</span> <span class="n">get_image_training_pipeline</span>

<span class="c1"># default pipeline with patch size 256 * 256 and a fixed random seed</span>
<span class="n">X_pipeline</span> <span class="o">=</span> <span class="n">get_image_training_pipeline</span><span class="p">(</span><span class="n">window_dims</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_pipeline</span>

<span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;channel_selector&#39;</span><span class="p">,</span> <span class="n">ChannelSelector</span><span class="p">(</span><span class="n">channels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])),</span>
    <span class="p">(</span><span class="s1">&#39;padder&#39;</span><span class="p">,</span> <span class="n">ArrayPadder</span><span class="p">(</span><span class="n">window_dims</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">))),</span>
    <span class="p">(</span><span class="s1">&#39;resampler&#39;</span><span class="p">,</span> <span class="n">ImageResampler</span><span class="p">(</span><span class="n">sf</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                                 <span class="n">preserve_int</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">resample_tolerance</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;tiler&#39;</span><span class="p">,</span> <span class="n">OverlappingTiler</span><span class="p">(</span><span class="n">window_dims</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">))),</span>
    <span class="p">(</span><span class="s1">&#39;synchronised_shuffler&#39;</span><span class="p">,</span> <span class="n">SynchronisedShuffler</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
<span class="p">])</span>
</pre></div>
</div>
<p>This will use the first three (usually RGB) channels of the input raster array,
pad this with zeros so that it divides evenly into multiples of the patch size,
perform no resampling (in this case), and divide up the large array into non-overlapping
patches of size 256 * 256 before finally shuffling these. See the detailed API
documentation for <code class="xref py py-mod docutils literal notranslate"><span class="pre">gim_cv.preprocessing</span></code> for details on the individual transformers.</p>
<p>Note that normalisation (or whitening) is not applied as a preprocessing step, and is
instead delegated to the batch generator functions (explained in the following sections).
This is because it can be useful to save the preprocessed arrays used for segmentation to
speed up training (so they don’t have to be generated every epoch from the source files),
and 8-bit integers representing RGB values are 4 x smaller than the 32-bit floats they will
be converted to at training time.</p>
<p>An analogous default pipeline for binary masks can be constructed with the function
<code class="xref py py-func docutils literal notranslate"><span class="pre">get_binary_mask_training_pipeline()</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gim_cv.preprocessing</span> <span class="kn">import</span> <span class="n">get_binary_mask_training_pipeline</span>

<span class="n">y_pipeline</span> <span class="o">=</span> <span class="n">get_binary_mask_training_pipeline</span><span class="p">(</span><span class="n">window_dims</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">y_pipeline</span>

<span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;dimension_adder&#39;</span><span class="p">,</span> <span class="n">DimensionAdder</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;padder&#39;</span><span class="p">,</span> <span class="n">ArrayPadder</span><span class="p">(</span><span class="n">window_dims</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">constant_values</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;resampler&#39;</span><span class="p">,</span> <span class="n">ImageResampler</span><span class="p">(</span><span class="n">sf</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                                 <span class="n">preserve_int</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">is_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">resample_tolerance</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;tiler&#39;</span><span class="p">,</span> <span class="n">OverlappingTiler</span><span class="p">(</span><span class="n">window_dims</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">))),</span>
    <span class="p">(</span><span class="s1">&#39;synchronised_shuffler&#39;</span><span class="p">,</span> <span class="n">SynchronisedShuffler</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
<span class="p">])</span>
</pre></div>
</div>
<p>This performs largely the same tasks, with the exception of adding a length-one channel
dimension to a binary mask so that multiclass and binary segmentation have data in the same
form.</p>
</section>
<section id="inference-pipelines">
<h2>Inference pipelines<a class="headerlink" href="#inference-pipelines" title="Permalink to this headline">¶</a></h2>
<p>Default pipelines for inference are similar, with the following caveats:</p>
<ul class="simple">
<li><p>Since the mask quality of semantic segmentation models is known to decline
near the edges and corners of each patch, it makes sense to use as large a
patch as possible during inference and a batch size of 1. The maximum size
is limited by the VRAM available in the GPU for feature maps and will differ
from machine to machine.</p></li>
<li><p>Shuffling is not necessary or desirable for inference since the spatial
ordering of patches should be preserved.</p></li>
<li><p>Normalisation and conversion into floats is performed as part of the preprocessing
pipeline since there is no batch generator function during inference (each patch is
exactly one batch). There is also no need to cache the arrays on disk since inference
takes one pass of a model over the input raster rather than many (as when training).</p></li>
</ul>
<p>A default inference pipeline is accessible via <code class="xref py py-func docutils literal notranslate"><span class="pre">get_image_inference_pipeline()</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gim_cv.preprocessing</span> <span class="kn">import</span> <span class="n">get_image_inference_pipeline</span>

<span class="n">X_pipeline</span> <span class="o">=</span> <span class="n">get_image_inference_pipeline</span><span class="p">(</span><span class="n">inference_window_size</span><span class="o">=</span><span class="mi">896</span><span class="p">)</span>
<span class="n">X_pipeline</span>

<span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;channel_selector&#39;</span><span class="p">,</span> <span class="n">ChannelSelector</span><span class="p">(</span><span class="n">channels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])),</span>
    <span class="p">(</span><span class="s1">&#39;array_padder&#39;</span><span class="p">,</span> <span class="n">ArrayPadder</span><span class="p">(</span><span class="mi">896</span><span class="p">,</span> <span class="mi">896</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;resampler&#39;</span><span class="p">,</span> <span class="n">ImageResampler</span><span class="p">(</span><span class="n">sf</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                                 <span class="n">preserve_int</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">resample_tolerance</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;tiler&#39;</span><span class="p">,</span> <span class="n">Tiler</span><span class="p">(</span><span class="n">window_dims</span><span class="o">=</span><span class="p">(</span><span class="mi">896</span><span class="p">,</span> <span class="mi">896</span><span class="p">))),</span>
    <span class="p">(</span><span class="s1">&#39;rechunker&#39;</span><span class="p">,</span> <span class="n">Rechunker</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))),</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">SimpleInputScaler</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mf">255.</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;float32er&#39;</span><span class="p">,</span> <span class="n">Float32er</span><span class="p">())</span>
<span class="p">])</span>
</pre></div>
</div>
<p>Note the <code class="xref py py-class docutils literal notranslate"><span class="pre">gim_cv.preprocessing.Rechunker</span></code> ensures that every dask chunk in
the array contains one patch, so a dask chunk is equivalent to a batch which is
convenient for just mapping a model over the chunks of the input dask array.</p>
</section>
<section id="custom-pipelines-for-specific-datasets">
<h2>Custom pipelines for specific datasets<a class="headerlink" href="#custom-pipelines-for-specific-datasets" title="Permalink to this headline">¶</a></h2>
<p>In certain cases the default pipelines won’t be exactly suitable for a given dataset.
This can happen for example if mask labels are encoded as rasters with specific RGB
values corresponding to different classes, and an additional step is required to
encode the labels as one-hot vectors or binary values.</p>
<p>In this case one can override the default pipelines either completely or by
prepending additional steps to the default ones.</p>
<p>When datasets defined in the <code class="xref py py-mod docutils literal notranslate"><span class="pre">datasets</span></code> module are used to construct
<code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingDataset</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">InferenceDataset</span></code>
objects (see <a class="reference internal" href="training.html"><span class="doc">Training</span></a> and <a class="reference internal" href="inference.html"><span class="doc">Inference</span></a>), these delegate to the functions
<code class="xref py py-func docutils literal notranslate"><span class="pre">get_image_training_pipeline_by_tag()</span></code>,
<code class="xref py py-func docutils literal notranslate"><span class="pre">get_binary_mask_training_pipeline_by_tag()</span></code> and
<code class="xref py py-func docutils literal notranslate"><span class="pre">get_image_inference_pipeline_by_tag()</span></code>. By default these functions
return the default pipelines outlined in the previous section. One can add dataset-specific
behaviour by overriding the logic of these functions.</p>
<p>All use-cases so far have fallen into the category where the additional logic is confined to
additional initial steps (after the extraction of the raster image/mask arrays). For convenience
there exist global dictionaries in <code class="xref py py-mod docutils literal notranslate"><span class="pre">gim_cv.datasets</span></code> module which allow one to inject
additional <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> Transformers based on the dataset tag. These will automatically be
looked in by the pipe getter functions and prepended.</p>
<p>For example, the dictionary <code class="xref py py-obj docutils literal notranslate"><span class="pre">gim_cv.datasets.BINARY_MASK_PIPELINE_PREP_STEPS</span></code> can be
used as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># in datasets.py...</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">gim_cv.config</span> <span class="k">as</span> <span class="nn">cfg</span>
<span class="kn">from</span> <span class="nn">gim_cv.preprocessing</span> <span class="kn">import</span> <span class="n">BinariserRGB</span>

<span class="c1"># define the massachusetts buildings dataset</span>
<span class="n">massach_buildings_path</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training_data_path</span> <span class="o">/</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;mass_buildings&#39;</span><span class="p">)</span>
<span class="n">ds_massa</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
    <span class="n">tag</span><span class="o">=</span><span class="s1">&#39;massachusetts&#39;</span><span class="p">,</span>
    <span class="n">spatial_resolution</span><span class="o">=</span><span class="mf">0.06</span><span class="p">,</span>
    <span class="n">image_paths</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">massach_buildings_path</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;train/sat/*&#39;</span><span class="p">)]),</span>
    <span class="n">mask_paths</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">massach_buildings_path</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;train/map/*&#39;</span><span class="p">)])</span>
<span class="p">)</span>

<span class="c1"># specify that the mask arrays should first pass through an RGB binariser</span>
<span class="c1"># (since buildings are encoded as red pixels in the source rasters)</span>
<span class="n">BINARY_MASK_PIPELINE_PREP_STEPS</span><span class="p">[</span><span class="s1">&#39;massachusetts&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;binariser&#39;</span><span class="p">,</span> <span class="n">BinariserRGB</span><span class="p">((</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)))</span>
<span class="p">]</span>
</pre></div>
</div>
<p>Now the mask pipeline associated with the dataset with the tag <code class="docutils literal notranslate"><span class="pre">massachusetts</span></code> will
automatically have this additional step.</p>
</section>
<section id="image-augmentation-transformers">
<h2>Image augmentation transformers<a class="headerlink" href="#image-augmentation-transformers" title="Permalink to this headline">¶</a></h2>
<p>Image augmentations are implemented using the <a class="reference external" href="https://github.com/albumentations-team/albumentations">albumentations</a> library. The function
<code class="xref py py-func docutils literal notranslate"><span class="pre">strong_aug()</span></code> returns an albumentations <code class="docutils literal notranslate"><span class="pre">Transformer</span></code> which
applies a set of image augmentations to batches with configurable probabilities. See the
function’s API documentation for more details.</p>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="models.html" class="btn btn-neutral float-right" title="Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="datasets.html" class="btn btn-neutral float-left" title="Datasets" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>